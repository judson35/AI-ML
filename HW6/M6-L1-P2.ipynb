{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (6 Points)\n",
    "\n",
    "In this problem you'll learn how to make a 'pipeline' in SciKit-Learn. A pipeline chains together multiple sklearn modules and runs them in series. For example, you can create a pipeline to perform feature scaling and then regression. For more information see https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/\n",
    "\n",
    "\n",
    "First, run the cell below to import modules and load data. Note the data axis scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x1 = np.array([10000.00548814, 10000.00715189, 10000.00602763, 10000.00544883, 10000.00423655, 10000.00645894, 10000.00437587, 10000.00891773, 10000.00963663, 10000.00383442, 10000.00791725, 10000.00528895, 10000.00568045, 10000.00925597, 10000.00071036, 10000.00087129, 10000.00020218, 10000.0083262 , 10000.00778157, 10000.00870012, 10000.00978618, 10000.00799159, 10000.00461479, 10000.00780529, 10000.00118274, 10000.00639921, 10000.00143353, 10000.00944669, 10000.00521848, 10000.00414662, 10000.00264556, 10000.00774234, 10000.0045615 , 10000.00568434, 10000.0001879 , 10000.00617635, 10000.00612096, 10000.00616934, 10000.00943748, 10000.0068182 , 10000.00359508, 10000.00437032, 10000.00697631, 10000.00060225, 10000.00666767, 10000.00670638, 10000.00210383, 10000.00128926, 10000.00315428, 10000.00363711, 10000.00570197, 10000.00438602, 10000.00988374, 10000.00102045, 10000.00208877, 10000.0016131 , 10000.00653108, 10000.00253292, 10000.00466311, 10000.00244426, 10000.0015897 , 10000.00110375, 10000.0065633 , 10000.00138183, 10000.00196582, 10000.00368725, 10000.00820993, 10000.00097101, 10000.00837945, 10000.00096098, 10000.00976459, 10000.00468651, 10000.00976761, 10000.00604846, 10000.00739264, 10000.00039188, 10000.00282807, 10000.00120197, 10000.0029614 , 10000.00118728, 10000.00317983, 10000.00414263, 10000.00064147, 10000.00692472, 10000.00566601, 10000.00265389, 10000.00523248, 10000.00093941, 10000.00575946, 10000.00929296, 10000.00318569, 10000.0066741 , 10000.00131798, 10000.00716327, 10000.00289406, 10000.00183191, 10000.00586513, 10000.00020108, 10000.0082894 , 10000.00004695])\n",
    "x2 = np.array([-184863.4856705 ,    1074.38382588,  -38090.38042426, -218261.93176495,   53942.6974416 ,   90630.02584275, 26090.16140437,  -96193.23522311, -176367.73593595, 14900.6554238 , -116285.92522759,   30020.05633442, -61255.25197308,    7897.51328353,  -47927.0242543 , -16408.41486272,  -79054.99813513,   80728.34445153, -68577.91165667,  -43820.95728998,   89483.56273506, -201298.31550282, -194343.64986372,    7245.70373422, -185581.10646027,   94925.90670844, -117225.70826838, -147270.93302967,   93064.78238323,   53246.3312291 , 88080.30643839,    1544.01924478, -157510.31165492, 91905.84577891, -104120.30338562,   -7778.92437832, 5252.67709964,  -93950.90837818,  -24732.85666885, 2998.60044099,  -46121.70219599, -178946.07115258, -53158.56432145,   39374.73070183, -142511.10737582, -93467.10862949, -119163.81965495,   86433.73556314, -19493.47186888,  -43328.4347383 , -149292.44670008, -31467.57278374, -140689.93945916,  -77135.24975531, -137226.1470541 ,  -19121.00345482,  -28106.82650466, -98746.88800202,  -44359.39586045, -178375.53578575, -214213.1833435 ,  -40454.74688619,  -64999.38541647, -22847.17067971,  134483.02973775,    5003.15382914, -162154.00028997,   20531.46592863, -198431.66694604, -121542.61443332,  -86141.74447922,   74200.84494844, -147027.93398436, -154379.46847931,  -88860.72719829, -139713.04577259,   21397.23298959, -177193.83575271, -183272.178717  , -119403.804027  , -124822.92056231, 93657.88484353,    5447.87262332,  -72120.38827533, -190289.19669472,   -4007.33212386, -170019.38126506, -219029.39870999,   26922.68131171,  -51475.16492676, 2877.29414027,  -51314.51123513,   -2885.24492876, -138592.30339701, -173081.8557606 ,  -18656.49335465, -152306.86977565, -142059.47999752, -120997.92531656, -78426.87568774])\n",
    "X = np.vstack([x1,x2]).T\n",
    "y = np.array([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.8)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x1,x2,c=y,cmap=\"viridis\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.title(\"Poorly-scaled data\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pipeline\n",
    "\n",
    "In this section, code to set up a pipeline has been given. Make note of how each step works:\n",
    "1. Create a scaler and classifier\n",
    "2. Put the scaler and classifier into a new pipeline\n",
    "3. Fit the pipeline to the training data\n",
    "4. Make predictions with the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler and a classifier\n",
    "scaler = MinMaxScaler()\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Put the scaler and classifier into a new pipeline\n",
    "pipeline = Pipeline([(\"MinMax Scaler\", scaler), (\"KNN Classifier\", model)])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the pipeline\n",
    "pred_train = pipeline.predict(X_train)\n",
    "pred_test = pipeline.predict(X_test)\n",
    "print(\"Training accuracy:\", accuracy_score(y_train, pred_train), \"   Testing accuracy:\", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing several pipelines\n",
    "\n",
    "Now, complete the code to create a new pipeline for every combination of scalers and models below:  \n",
    "\n",
    "Scalers:\n",
    "- None\n",
    "- MinMax\n",
    "- Standard\n",
    "\n",
    "\n",
    "Classifiers:\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- KNN Classifier, 1 neighbor\n",
    "\n",
    "\n",
    "Within the loop, a scaler and model are created. You will create a pipeline, fit it to the training data, and make predictions on testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(i):\n",
    "    if i == 0:\n",
    "        return (\"No Scaler\", None)\n",
    "    elif i == 1:\n",
    "        return (\"MinMax Scaler\", MinMaxScaler())\n",
    "    elif i == 2:\n",
    "        return (\"Standard Scaler\", StandardScaler())\n",
    "\n",
    "def get_model(i):\n",
    "    if i == 0:\n",
    "        return (\"Logistic Regression\", LogisticRegression())\n",
    "    elif i == 1:\n",
    "        return (\"Support Vector Classifier\", SVC())\n",
    "    elif i == 2:\n",
    "        return (\"1-NN Classifier\", KNeighborsClassifier(n_neighbors=1))\n",
    "\n",
    "for scaler_index in range(3):\n",
    "    for model_index in range(3):\n",
    "        scaler = get_scaler(scaler_index)\n",
    "        model = get_model(model_index)\n",
    "\n",
    "        # YOUR CODE GOES HERE\n",
    "        # Create a pipeline\n",
    "        # Fit the pipeline on X_train, y_train\n",
    "        # Calculate acc_train and acc_test for the pipeline\n",
    "\n",
    "        print(f\"{scaler[0]:>15},{model[0]:>26}:    Train Acc. = {100*acc_train:5.1f}%    Test Acc. = {100*acc_test:5.1f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Answer the following questions:  \n",
    "\n",
    "1. Which model's testing accuracy was improved the most by scaling data?  \n",
    "\n",
    "\n",
    "2. Which performs better on this data: MinMax scaler, Standard scaler, or neither?  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
