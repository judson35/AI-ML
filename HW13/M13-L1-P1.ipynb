{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13-L1 Problem 1\n",
    "\n",
    "We return to the plane-strain compression problem where the goal is to predict von Mises stress at a node given a set of its features.\n",
    "\n",
    "Now, you will look at ensemble methods in sklearn to determine how well they perform in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "def plot_shape(dataset, index, model=None, lims=None):\n",
    "    x = dataset[\"coordinates\"][index][:,0]\n",
    "    y = dataset[\"coordinates\"][index][:,1]\n",
    "\n",
    "    if model is None:\n",
    "        c = dataset[\"stress\"][index]\n",
    "    else:\n",
    "        c = model.predict(dataset[\"features\"][index])\n",
    "\n",
    "    if lims is None:\n",
    "        lims = [min(c),max(c)]    \n",
    "\n",
    "    plt.scatter(x,y,s=5,c=c,cmap=\"jet\",vmin=lims[0],vmax=lims[1])\n",
    "    plt.colorbar(orientation=\"horizontal\", shrink=.75, pad=0,ticks=lims)\n",
    "    plt.axis(\"off\")\n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "def plot_shape_comparison(dataset, index, model, title=\"\"):\n",
    "    plt.figure(figsize=[6,3.2], dpi=120)\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_shape(dataset,index)\n",
    "    plt.title(\"Ground Truth\",fontsize=9,y=.96)\n",
    "    plt.subplot(1,2,2)\n",
    "    c = dataset[\"stress\"][index]\n",
    "    plot_shape(dataset, index, model, lims = [min(c), max(c)])\n",
    "    plt.title(\"Prediction\",fontsize=9,y=.96)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = np.load(path)\n",
    "    coordinates = []\n",
    "    features = []\n",
    "    stress = []\n",
    "    N = np.max(dataset[:,0].astype(int)) + 1\n",
    "    split = int(N*.8)\n",
    "    for i in range(N):\n",
    "        idx = dataset[:,0].astype(int) == i\n",
    "        data = dataset[idx,:]\n",
    "        coordinates.append(data[:,1:3])\n",
    "        features.append(data[:,3:-1])\n",
    "        stress.append(data[:,-1])\n",
    "    dataset_train = dict(coordinates=coordinates[:split], features=features[:split], stress=stress[:split])\n",
    "    dataset_test = dict(coordinates=coordinates[split:], features=features[split:], stress=stress[split:])\n",
    "    X_train, X_test = np.concatenate(features[:split], axis=0), np.concatenate(features[split:], axis=0)\n",
    "    y_train, y_test = np.concatenate(stress[:split], axis=0), np.concatenate(stress[split:], axis=0)\n",
    "    return dataset_train, dataset_test, X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_shape(dataset,index):\n",
    "    X = dataset[\"features\"][index]\n",
    "    y = dataset[\"stress\"][index]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First, complete the code below to load the data and plot the von Mises stress fields for a few shapes.  \n",
    "You'll need to input the path of the data file, the rest is done for you. \n",
    "\n",
    "All training node features and outputs are in `X_train` and `y_train`, respectively. Testing nodes are in `X_test`, `y_test`.  \n",
    "\n",
    "`dataset_train` and `dataset_test` contain more detailed information such as node coordinates, and they are separated by shape.  \n",
    "Get features and outputs for a shape by calling `get_shape(dataset,index)`. `N_train` and `N_test` are the number of training and testing shapes in each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MAY NEED TO EDIT data_path\n",
    "data_path = \"stress_nodal_features.npy\"\n",
    "dataset_train, dataset_test, X_train, X_test, y_train, y_test = load_dataset(data_path)\n",
    "N_train = len(dataset_train[\"stress\"])\n",
    "N_test = len(dataset_test[\"stress\"])\n",
    "\n",
    "plt.figure(figsize=[15,3.2], dpi=150)\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plot_shape(dataset_train,i)\n",
    "    plt.title(f\"Shape {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingRegressor\n",
    "\n",
    "A StackingRegressor consists of $N$ fitted regression models, which it evaluates to make $N$ predictions. Then, these predictions are fed into another regression model, which makes a final prediction of the target.\n",
    "\n",
    "### List of Regressors\n",
    "First, initialize 4 regression models:\n",
    "1. Linear Regression\n",
    "2. Decision Tree regression, max depth 4\n",
    "3. Decision Tree regression, max depth 8\n",
    "4. Decision Tree regression, max depth 12\n",
    "\n",
    "Then, store these in a list called `models`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# Define models, and put in a list called 'models'\n",
    "\n",
    "named_models = [(f\"Model {i+1}\", model) for i, model in enumerate(models)]\n",
    "print(*named_models, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Regressor\n",
    "Now make one more regressor, which will take as input the other four predictions, and combine them to make an improved prediction. \n",
    "\n",
    "This can be another linear regression model. Call it `final_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and training the StackingRegressor\n",
    "\n",
    "Finally, we can combine all of our models into a StackingRegressor model. We fit this just as we would fit any sklearn model. Because of the size of the dataset, this may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srm = StackingRegressor(named_models, final_model, verbose=True)\n",
    "srm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the model\n",
    "\n",
    "Now we can investigate the performance of the model on test data, compared to constituent models. First, let's look at the performance of each individual model of our model `srm`. These can be accessed via `srm.estimators_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, estimator in enumerate(srm.estimators_):\n",
    "    print(f\"\\n{named_models[i][0]}:\")\n",
    "    train_err = mean_squared_error(y_train, estimator.predict(X_train))\n",
    "    test_err = mean_squared_error(y_test, estimator.predict(X_test))\n",
    "    print(f\"Training MSE: {train_err:.2e}\")\n",
    "    print(f\" Testing MSE: {test_err:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Regressor MSE on Test Data\n",
    "Now compute the MSE of `srm` on training and testing data.\n",
    "\n",
    "Note how the results, particularly on test data, compare to the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
