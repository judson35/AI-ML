{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M13-L2 Problem 1\n",
    "\n",
    "Once more, we will study the stress prediction problem, this time using XGBoost, a very powerful boosting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def plot_shape(dataset, index, model=None, lims=None):\n",
    "    x = dataset[\"coordinates\"][index][:,0]\n",
    "    y = dataset[\"coordinates\"][index][:,1]\n",
    "\n",
    "    if model is None:\n",
    "        c = dataset[\"stress\"][index]\n",
    "    else:\n",
    "        c = model.predict(dataset[\"features\"][index])\n",
    "\n",
    "    if lims is None:\n",
    "        lims = [min(c),max(c)]    \n",
    "\n",
    "    plt.scatter(x,y,s=5,c=c,cmap=\"jet\",vmin=lims[0],vmax=lims[1])\n",
    "    plt.colorbar(orientation=\"horizontal\", shrink=.75, pad=0,ticks=lims)\n",
    "    plt.axis(\"off\")\n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "def plot_shape_comparison(dataset, index, model, title=\"\"):\n",
    "    plt.figure(figsize=[6,3.2], dpi=120)\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_shape(dataset,index)\n",
    "    plt.title(\"Ground Truth\",fontsize=9,y=.96)\n",
    "    plt.subplot(1,2,2)\n",
    "    c = dataset[\"stress\"][index]\n",
    "    plot_shape(dataset, index, model, lims = [min(c), max(c)])\n",
    "    plt.title(\"Prediction\",fontsize=9,y=.96)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = np.load(path)\n",
    "    coordinates = []\n",
    "    features = []\n",
    "    stress = []\n",
    "    N = np.max(dataset[:,0].astype(int)) + 1\n",
    "    split = int(N*.8)\n",
    "    for i in range(N):\n",
    "        idx = dataset[:,0].astype(int) == i\n",
    "        data = dataset[idx,:]\n",
    "        coordinates.append(data[:,1:3])\n",
    "        features.append(data[:,3:-1])\n",
    "        stress.append(data[:,-1])\n",
    "    dataset_train = dict(coordinates=coordinates[:split], features=features[:split], stress=stress[:split])\n",
    "    dataset_test = dict(coordinates=coordinates[split:], features=features[split:], stress=stress[split:])\n",
    "    X_train, X_test = np.concatenate(features[:split], axis=0), np.concatenate(features[split:], axis=0)\n",
    "    y_train, y_test = np.concatenate(stress[:split], axis=0), np.concatenate(stress[split:], axis=0)\n",
    "    return dataset_train, dataset_test, X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_shape(dataset,index):\n",
    "    X = dataset[\"features\"][index]\n",
    "    y = dataset[\"stress\"][index]\n",
    "    return X, y\n",
    "\n",
    "def eval_model(model, verbose=False):\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, pred_train)\n",
    "    mse_test = mean_squared_error(y_test, pred_test)\n",
    "    if verbose:\n",
    "        print(f\"Train MSE = {mse_train:.2e}\")\n",
    "        print(f\"Test  MSE = {mse_test:.2e}\")\n",
    "    return mse_train, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First, complete the code below to load the data and plot the von Mises stress fields for a few shapes.  \n",
    "You'll need to input the path of the data file, the rest is done for you. \n",
    "\n",
    "All training node features and outputs are in `X_train` and `y_train`, respectively. Testing nodes are in `X_test`, `y_test`.  \n",
    "\n",
    "`dataset_train` and `dataset_test` contain more detailed information such as node coordinates, and they are separated by shape.  \n",
    "Get features and outputs for a shape by calling `get_shape(dataset,index)`. `N_train` and `N_test` are the number of training and testing shapes in each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU MAY NEED TO EDIT data_path\n",
    "data_path = \"stress_nodal_features.npy\"\n",
    "dataset_train, dataset_test, X_train, X_test, y_train, y_test = load_dataset(data_path)\n",
    "N_train = len(dataset_train[\"stress\"])\n",
    "N_test = len(dataset_test[\"stress\"])\n",
    "\n",
    "plt.figure(figsize=[15,3.2], dpi=150)\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plot_shape(dataset_train,i)\n",
    "    plt.title(f\"Shape {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor\n",
    "\n",
    "XGBoost models, like `XGBRegressor` here, can be used much like sklearn models. \n",
    "\n",
    "First, define an instance of `XGBRegressor` with the desired parameters; then, fit the model with `model.fit`. You can evaluate a fitted model with `model.predict`.\n",
    "\n",
    "The provided function `mse_train, mse_test = eval_model(model)` to get MSE values on the train and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.8\n",
    "depth = 9\n",
    "\n",
    "params = dict(\n",
    "    eta = eta,\n",
    "    max_depth = depth,\n",
    ")\n",
    "\n",
    "model = XGBRegressor(objective ='reg:squarederror', seed = 123, n_estimators = 10, **params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mse_train, mse_test = eval_model(model)\n",
    "print(\"  eta   depth   |   Train MSE    Test MSE\")\n",
    "print(\"----------------|--------------------------\")\n",
    "print(f\"  {eta:.1f}    {depth:>2d}     |    {mse_train:.2e}    {mse_test:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric study\n",
    "\n",
    "Now let's examine the effects of varying the parameters `eta` and `max_depth`, keeping `n_estimators` as 10.\n",
    "For every combination of eta in [0.1, 0.3, 0.5, 0.7] and `max_depth` in [5, 10, 15, 20], train an XGB regressor and report the train and test MSE values.\n",
    "\n",
    "Which combination has the best performance on testing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
