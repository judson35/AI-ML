{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M7-L1 Problem 2\n",
    "\n",
    "In this problem, you will explore what happens when you change the weights/biases of a neural network.\n",
    "\n",
    "Neural networks act as functions that attempt to map from input data to output data. In training a neural network, the goal is to find the values of weights and biases that minimize the loss between their output and the desired output. This is typically done with a technique called backpropagation; however, here you will simply note the effect of changing specific weights in the network which has been pre-trained.\n",
    "\n",
    "First, load the data and initial weights/biases below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([0.        , 0.03448276, 0.06896552, 0.10344828, 0.13793103,0.17241379, 0.20689655, 0.24137931, 0.27586207, 0.31034483,0.34482759, 0.37931034, 0.4137931 , 0.44827586, 0.48275862,0.51724138, 0.55172414, 0.5862069 , 0.62068966, 0.65517241,0.68965517, 0.72413793, 0.75862069, 0.79310345, 0.82758621,0.86206897, 0.89655172, 0.93103448, 0.96551724, 1.        ]).reshape(-1,1)\n",
    "y = np.array([ 0.38914369,  0.40997345,  0.40282978,  0.38493705,  0.394214  ,0.41651437,  0.37573321,  0.39571087,  0.41265936,  0.41953955,0.50596807,  0.58059196,  0.6481607 ,  0.66050901,  0.67741369,0.67348567,  0.67696078,  0.63537378,  0.56446933,  0.48265412,0.39540671,  0.29878237,  0.15893846,  0.05525194, -0.10070259,-0.23055219, -0.35288448, -0.51317604, -0.63377544, -0.76849408]).reshape(-1,1)\n",
    "\n",
    "weights = [np.array([[-5.90378086,  0,  0 ]]).T,\n",
    "           np.array([[ 0.8996511 ,  4.75805319, -0.95266992],[-0.99667812, -0.89303165,  3.19020423],[-1.65213421, -2.93268438,  2.61332701]]).T,\n",
    "           np.array([[ 1.71988943, -1.56198034, -3.31173131]])]\n",
    "\n",
    "biases = [np.array([ 2.02112296, -3.47589349, -1.11586831]), np.array([ 1.35350721, -0.11181542, -4.0283719 ]), np.array([0.51626399])]\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.scatter(x,y,s=5,c=\"navy\",label=\"Data\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Function\n",
    "Copy in your MLP function (and all necessary helper functions) below. Make sure it is called `MLP()`. In this case, you can plug in `x`, `weights`, and `biases` to try and predict `y`. Make sure you use the sigmoid activation function after each layer (except the final layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying weights\n",
    "\n",
    "\n",
    "The provided network has 2 hidden layers, each with 3 neurons. The weights and biases are shown below.\n",
    "Note the weights $w_a$ and $w_b$ -- these are left for you to investigate:\n",
    "\n",
    "$$\n",
    "\\underline{x\\; (N\\times 1)} \\rightarrow\n",
    "\\sigma\\left(w = \n",
    "\\begin{bmatrix}\n",
    "  -5.9\\\\\n",
    "  \\boldsymbol{w_a}\\\\\n",
    "  \\boldsymbol{w_b}\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    ";b = \n",
    "\\begin{bmatrix}\n",
    "  2.02\\\\\n",
    "  -3.48\\\\\n",
    "  -1.12\\\\\n",
    "\\end{bmatrix}'\n",
    "\n",
    "\\right)\\rightarrow\n",
    "\n",
    "\n",
    "\\underline{(N\\times 3)} \\rightarrow\n",
    "\\sigma\\left(w = \n",
    "\\begin{bmatrix}\n",
    "  0.9 & -1. & -1.65\\\\\n",
    "  4.76 & -0.89 & -2.93\\\\\n",
    "  -0.95 & 3.19 & 2.61\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    ";b = \n",
    "\\begin{bmatrix}\n",
    "  1.35\\\\\n",
    "  -0.11\\\\\n",
    "  -4.03\\\\\n",
    "\\end{bmatrix}'\n",
    "\n",
    "\n",
    "\n",
    "\\right)\\rightarrow\n",
    "\n",
    "\\underline{(N\\times 3)} \\rightarrow\n",
    "\\sigma\\left(w = \n",
    "\\begin{bmatrix}\n",
    "  1.72\\\\ -1.56\\\\ -3.31\\\\\n",
    "\\end{bmatrix}'\n",
    "\n",
    ";b = \n",
    "\\begin{bmatrix}\n",
    "  0.52\\\\\n",
    "\\end{bmatrix}'\n",
    "\n",
    "\\right)\\rightarrow\n",
    "\\underline{\\hat{y}\\; (N\\times 1)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "We can compute the MSE for each combination of $(w_a, w_b)$ to see where MSE is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, pred):\n",
    "    return np.mean((y.flatten()-pred.flatten())**2)\n",
    "\n",
    "vals = np.linspace(0,12,100)\n",
    "was, wbs = np.meshgrid(vals,vals)\n",
    "mses = np.zeros_like(was.flatten())\n",
    "\n",
    "for i in range(len(was.flatten())):\n",
    "    ws, bs = weights.copy(), biases.copy()\n",
    "    ws[0][1,0] = was.flatten()[i]\n",
    "    ws[0][2,0] = wbs.flatten()[i]\n",
    "    mses[i] = MSE(y, MLP(x, ws, bs))\n",
    "mses = mses.reshape(was.shape)\n",
    "\n",
    "plt.figure(figsize = (3.5,3),dpi=150)\n",
    "plt.title(\"MSE\")\n",
    "plt.contour(was,wbs,mses,colors=\"black\")\n",
    "plt.pcolormesh(was,wbs,mses,shading=\"nearest\",cmap=\"coolwarm\")\n",
    "plt.xlabel(\"$w_a$\")\n",
    "plt.ylabel(\"$w_b$\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout, FloatSlider, Dropdown\n",
    "\n",
    "\n",
    "def plot(wa, wb):\n",
    "    ws, bs = weights.copy(), biases.copy()\n",
    "    ws[0][1,0] = wa\n",
    "    ws[0][2,0] = wb\n",
    "\n",
    "    xs = np.linspace(0,1)\n",
    "    ys = MLP(xs.reshape(-1,1), ws, bs)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,4),dpi=120)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.contour(was,wbs,mses,colors=\"black\")\n",
    "    plt.pcolormesh(was,wbs,mses,shading=\"nearest\",cmap=\"coolwarm\")\n",
    "    plt.title(f\"$w_a = {wa:.1f}$;  $w_b = {wb:.1f}$\")\n",
    "    plt.xlabel(\"$w_a$\")\n",
    "    plt.ylabel(\"$w_b$\")\n",
    "    plt.scatter(wa,wb,marker=\"*\",color=\"black\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(x,y,s=5,c=\"navy\",label=\"Data\")\n",
    "    plt.plot(xs,ys,\"r-\",linewidth=1,label=\"MLP\")\n",
    "    plt.title(f\"MSE = {MSE(y, MLP(x, ws, bs)):.3f}\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "slider1 = FloatSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=12,\n",
    "    step=.5,\n",
    "    description='wa',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=False,\n",
    "    layout = Layout(width='550px')\n",
    ")\n",
    "\n",
    "slider2 = FloatSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=12,\n",
    "    step=.5,\n",
    "    description='wb',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=False,\n",
    "    layout = Layout(width='550px')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "interactive_plot = interactive(\n",
    "    plot,\n",
    "    wa = slider1,\n",
    "    wb = slider2\n",
    "    )\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '500px'\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. For $w_a = 4.0$, what walue of $w_b$ gives the lowest MSE (to the nearest 0.5)?\n",
    "- *ANSWER:*  \n",
    "\n",
    "2. For the large values of $w_a$ and $w_b$, describe the MLP's predictions.\n",
    "- *ANSWER:* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
