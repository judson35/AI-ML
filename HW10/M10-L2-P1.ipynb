{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M10-L2 Problem 1\n",
    "\n",
    "In this problem, you will perform 10-fold cross validation to find the best of 3 regression models.\n",
    "\n",
    "You are given a dataset with testing and training data of another radial distribution function (measuring 'g(r)', the probability of a particle being a certain distance 'r' from another particle): `X_train, X_test, y_train, y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def get_gr(r):\n",
    "    a, b, L, m, t, d = 0.54, 5.4, 1.2, 7.4, 100, 3.3\n",
    "    g1 = 1 + (r+1e-9)**(-m) * (d-1-L) + (r-1+L)/(r+1e-9)*np.exp(-a*(r-1))*np.cos(b*(r-1))\n",
    "    g2 = d * np.exp(-t*(r-1)**2)\n",
    "    g = g1*(r>=1) + g2*(r<1)\n",
    "    return g\n",
    "\n",
    "def plot_model(model,color=\"blue\"):\n",
    "    x = np.linspace(0, 5, 1000)\n",
    "    y = model.predict(x.reshape(-1,1))\n",
    "    plt.plot(x, y, color=color, linewidth=2, zorder=2)\n",
    "    plt.xlabel(\"r\")\n",
    "    plt.ylabel(\"g(r)\")\n",
    "\n",
    "def plot_data(x, y):\n",
    "    plt.scatter(x,y,s=1, color=\"black\")\n",
    "    plt.xlabel(\"r\")\n",
    "    plt.ylabel(\"g(r)\")\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0,5,1000).reshape(-1,1)\n",
    "y = np.random.normal(get_gr(X.flatten()),0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=800)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_data(X,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "Below we define 3 sklearn neural network models `model1`, `model2`, and `model3`. Your goal is to find which is best using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MLPRegressor([24], random_state=0, activation=\"tanh\", max_iter=1000)\n",
    "model2 = MLPRegressor([48,48], random_state=0, activation=\"tanh\", max_iter=1000)\n",
    "model3 = MLPRegressor([64,64, 64], random_state=0, activation=\"relu\", max_iter=1000)\n",
    "\n",
    "\n",
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation folds\n",
    "\n",
    "\n",
    "This cell creates 10-fold iterator objects in sklearn. Make note of how this is done.\n",
    "\n",
    "We also provide code for computing the cross-validation score for average $R^2$ over validation folds. Note that the model is retrained on each fold, and weights/biases are reset each time with `sklearn.base.clone()`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10,random_state=0,shuffle=True)\n",
    "\n",
    "\n",
    "scores1 = []\n",
    "for train_idx, val_idx in folds.split(X_train):\n",
    "    model1 = clone(model1)\n",
    "    model1.fit(X_train[train_idx,:],y_train[train_idx])\n",
    "    score = model1.score(X_train[val_idx,:],y_train[val_idx])\n",
    "    scores1.append(score)\n",
    "    print(f\"Validation score: {score}\")\n",
    "\n",
    "\n",
    "score1 = np.mean(np.array(scores1))\n",
    "print(f\"Average validation score for Model 1: {score1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn: validating models 2 and 3\n",
    "\n",
    "Now follow the same procedure to get the average $R^2$ scores for `model2` and `model3` on validation folds. You can use the same KFold iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models\n",
    "\n",
    "Which model had the best performance according to your validation study?\n",
    "\n",
    "Retrain this model on the full training dataset and report the R2 score on training and testing data. Then complete the code to plot the model prediction with the data using the `plot_model` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_data(X,y)\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
