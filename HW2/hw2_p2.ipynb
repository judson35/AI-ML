{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"q5RCSXD8zXH1"},"source":["# Homework 2 Programming Problem 2 (5 points)\n","\n","Consider the following data:\n","\n","![Cubic data](https://drive.google.com/uc?id=1uXGTKAIj3Zo4C5vSACCIVkmuZoG0Pyhv)\n","\n","\n","We will perform these steps:\n","1. Load the data\n","2. Generate a design matrix\n","3. Solve for the regression coefficients\n","4. Create and plot a curve using these coefficients\n","\n","First, we demonstrate the above for a linear (1st order) model. First, run each cell in the demo and follow along with each step. Your job is then to make 2nd and 3rd order models for the same data using similar techniques.\n","\n","## Demonstration: Linear fit\n","\n","First, we load the data in to x and y:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9vIXhBKPFg9"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","x = np.array([0.2855, 0.0033, 0.8307, 0.9606, 0.8153, 0.5539, 0.5152, 0.7761,\n","       0.5763, 0.2697, 0.6744, 0.7998, 0.1052, 0.8674, 0.598 , 0.3985,\n","       0.0171, 0.1732, 0.7976, 0.4137, 0.7161, 0.7225, 0.3892, 0.0834,\n","       0.9733, 0.3097, 0.8509, 0.0226, 0.6901, 0.2235, 0.5914, 0.5436,\n","       0.7189, 0.4558, 0.8366, 0.534 , 0.214 , 0.9314, 0.4065, 0.788 ])\n","\n","y = np.array([ 0.6603, -0.5925,  0.2045,  0.3698,  0.191 ,  0.496 ,  0.4986,\n","        0.2516,  0.3905,  0.5932,  0.2924,  0.219 ,  0.0287,  0.2024,\n","        0.4489,  0.6237, -0.4857,  0.3384,  0.162 ,  0.6694,  0.2539,\n","        0.1936,  0.6322, -0.0953,  0.4632,  0.6721,  0.2464, -0.4672,\n","        0.2746,  0.5087,  0.3691,  0.4559,  0.2021,  0.5797,  0.2531,\n","        0.5417,  0.4577,  0.2952,  0.5856,  0.1818])\n"]},{"cell_type":"markdown","metadata":{"id":"8JbswcuCJdrc"},"source":["Now we generate a linear design matrix for the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dui-gxUDEHNb"},"outputs":[],"source":["# Function to get a linear design matrix for 1D data\n","def get_linear_design_matrix(x):\n","    x = x.reshape(-1, 1)                # Turn x into a column array\n","    columns = [x, np.ones_like(x)]      # Linear design matrix has a column of x and a column of ones\n","    X = np.concatenate(columns, axis=1) # Combine each column horizontally to make a matrix\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1677641918928,"user":{"displayName":"Kevin Ferguson","userId":"00256100345430567757"},"user_tz":300},"id":"c--2XPTJE6Oo","outputId":"65699f48-42e1-4a19-d370-9aa85e68c546"},"outputs":[],"source":["X = get_linear_design_matrix(x)\n","print(\"First four rows of X:\")\n","print(X[:4,:])"]},{"cell_type":"markdown","metadata":{"id":"lxg4v9DaGL8P"},"source":["Now that we have the design matrix $X$ and the output $y$, we can solve for the coefficients $w$ such that $X w \\approx y$ using:\n","$$\n","w = (X'\\, X)^{-1}\\, X'\\, y\n","$$\n","\n","Note the use of the following in Python:\n","- `@` for matrix multiplication\n","- `np.inv(A)` for inversion of matrix `A`\n","- `A.T` for transpose of a matrix `A`\n","- `b.reshape(-1,1)` to treat 1D array `b` as a column\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1677641919817,"user":{"displayName":"Kevin Ferguson","userId":"00256100345430567757"},"user_tz":300},"id":"RCTUzUkvFYZ9","outputId":"01d58e62-e131-4e64-c0b4-6985c3fdacaf"},"outputs":[],"source":["# Get coefficients \n","w = np.linalg.inv(X.T @ X) @ X.T @ y.reshape(-1,1)\n","print(\"Linear Coefficients:\", w.flatten())"]},{"cell_type":"markdown","metadata":{"id":"McXwS5-yIjJd"},"source":["Next, we write a plotting function to plot data and our least squares regression on the same axes. To apply our regression we can call the `get_linear_design_matrix()` function on a new set of x values and multiply the result by our coefficients `w`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5DOLEfDIigr"},"outputs":[],"source":["def plot_data_with_regression(x_data, y_data, x_reg, y_reg):\n","    plt.figure()\n","\n","    plt.scatter(x_data, y_data, label=\"Data\", c=\"black\")\n","    plt.plot(x_reg, y_reg, label=\"Fit\")\n","\n","    plt.legend()\n","    plt.xlabel(r\"$x_1$\")\n","    plt.ylabel(r\"$y$\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":577,"status":"ok","timestamp":1677641922591,"user":{"displayName":"Kevin Ferguson","userId":"00256100345430567757"},"user_tz":300},"id":"k4FkZ6nSJ3Ad","outputId":"2eb5b1a1-c41b-40a8-e595-5c959c2b2614"},"outputs":[],"source":["x_fit = np.linspace(0, 1, 100)                # x values for fit line\n","y_fit = get_linear_design_matrix(x_fit) @ w   # y values for fit line\n","\n","plot_data_with_regression(x, y, x_fit, y_fit)"]},{"cell_type":"markdown","metadata":{"id":"4myRkeuEKvLw"},"source":["## Your turn: Second order polynomial\n","\n","Now you will solve the same problem, but with a quadratic polynomial instead of linear. We need to write a new function to generate a design matrix.\n","\n","Replace the commented code below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dj-7zTyUVfF"},"outputs":[],"source":["def get_quadratic_design_matrix(x):\n","    # YOUR CODE GOES HERE\n","    # GENERATE A DESIGN MATRIX WITH 2ND ORDER FEATURES: X\n","\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l97kcHOrLkqS"},"outputs":[],"source":["X = get_quadratic_design_matrix(x)\n","print(\"First four rows of X:\")\n","print(X[:4,:])"]},{"cell_type":"markdown","metadata":{"id":"REth3AEOLeEx"},"source":["Compute the `w` coefficients with a pseudo-inverse as in the example:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibvIHZLuLX2P"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# COMPUTE COEFFICIENTS w\n","\n","print(\"Quadratic Coefficients:\", w.flatten())"]},{"cell_type":"markdown","metadata":{"id":"oTcPnxfwMV8T"},"source":["Now plot by generating a regression curve and calling the `plot_data_with_regression()` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9EuZEPgMTmg"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# PLOT"]},{"cell_type":"markdown","metadata":{"id":"-Jq5hDdVMoFx"},"source":["## 3rd Order Polynomial\n","\n","Here we go through the same steps as above, but this time we perform a cubic polynomial fit. Once again, fill in the necessary code:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wrosOBGM0Ti"},"outputs":[],"source":["def get_cubic_design_matrix(x):\n","    # YOUR CODE GOES HERE\n","    # GENERATE A DESIGN MATRIX WITH 3RD ORDER FEATURES: X\n","\n","    return X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TrxPyLHvM7Ov"},"outputs":[],"source":["X = get_cubic_design_matrix(x)\n","print(\"First four rows of X:\")\n","print(X[:4,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dGkEI4xNPUb6"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# COMPUTE COEFFICIENTS w\n","\n","print(\"Cubic Coefficients:\", w.flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RzTskWLbPewj"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# PLOT\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
