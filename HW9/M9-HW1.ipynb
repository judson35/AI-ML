{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1:\n",
    "\n",
    "Once again consider the plane-strain compression problem shown in \"data/plane-strain.png\". In this problem you are given node features for 100 parts. These node features have been extracted by processing each part shape using a neural network. You will train a neural network to von Mises stress at each node given its 60 features. Then you will analyze $R^2$ for the training and testing data, both for the full dataset and for individual shapes within each dataset.\n",
    "\n",
    "#### Summary of deliverables\n",
    "\n",
    "- Neural network model definition\n",
    "- Training function\n",
    "- Training loss curve\n",
    "- Overall $R^2$ on training and testing data\n",
    "- Predicted-vs-actual plots for training and testing data\n",
    "- Histograms of $R^2$ distributions on training and testing shapes\n",
    "- Median $R^2$ values across training and testing shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "def plot_shape(dataset, index, model=None, lims=None):\n",
    "    x = dataset[\"coordinates\"][index][:,0]\n",
    "    y = dataset[\"coordinates\"][index][:,1]\n",
    "\n",
    "    if model is None:\n",
    "        c = dataset[\"stress\"][index]\n",
    "    else:\n",
    "        c = model(torch.tensor(dataset[\"features\"][index])).detach().numpy().flatten()\n",
    "\n",
    "    if lims is None:\n",
    "        lims = [min(c),max(c)]    \n",
    "\n",
    "    plt.scatter(x,y,s=5,c=c,cmap=\"jet\",vmin=lims[0],vmax=lims[1])\n",
    "    plt.colorbar(orientation=\"horizontal\", shrink=.75, pad=0,ticks=lims)\n",
    "    plt.axis(\"off\")\n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "def plot_shape_comparison(dataset, index, model, title=\"\"):\n",
    "    plt.figure(figsize=[6,3.2], dpi=120)\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_shape(dataset,index)\n",
    "    plt.title(\"Ground Truth\",fontsize=9,y=.96)\n",
    "    plt.subplot(1,2,2)\n",
    "    c = dataset[\"stress\"][index]\n",
    "    plot_shape(dataset, index, model, lims = [min(c), max(c)])\n",
    "    plt.title(\"Prediction\",fontsize=9,y=.96)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = np.load(path)\n",
    "    coordinates = []\n",
    "    features = []\n",
    "    stress = []\n",
    "    N = np.max(dataset[:,0].astype(int)) + 1\n",
    "    split = int(N*.8)\n",
    "    for i in range(N):\n",
    "        idx = dataset[:,0].astype(int) == i\n",
    "        data = dataset[idx,:]\n",
    "        coordinates.append(data[:,1:3])\n",
    "        features.append(data[:,3:-1])\n",
    "        stress.append(data[:,-1])\n",
    "    dataset_train = dict(coordinates=coordinates[:split], features=features[:split], stress=stress[:split])\n",
    "    dataset_test = dict(coordinates=coordinates[split:], features=features[split:], stress=stress[split:])\n",
    "    X_train, X_test = np.concatenate(features[:split], axis=0), np.concatenate(features[split:], axis=0)\n",
    "    y_train, y_test = np.concatenate(stress[:split], axis=0), np.concatenate(stress[split:], axis=0)\n",
    "    return dataset_train, dataset_test, X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_shape(dataset,index):\n",
    "    X = torch.tensor(dataset[\"features\"][index])\n",
    "    Y = torch.tensor(dataset[\"stress\"][index].reshape(-1,1))\n",
    "    return X, Y\n",
    "\n",
    "def plot_r2_distribution(r2s, title=\"\"):\n",
    "    plt.figure(dpi=120,figsize=(6,4))\n",
    "    plt.hist(r2s, bins=10)\n",
    "    plt.xlabel(\"$R^2$\")\n",
    "    plt.ylabel(\"Number of shapes\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First, complete the code below to load the data and plot the von Mises stress fields for a few shapes.  \n",
    "You'll need to input the path of the data file, the rest is done for you. \n",
    "\n",
    "All training node features and outputs are in `X_train` and `y_train`, respectively. Testing nodes are in `X_test`, `y_test`.  \n",
    "\n",
    "`dataset_train` and `dataset_test` contain more detailed information such as node coordinates, and they are separated by shape.  \n",
    "Get features and outputs for a shape by calling `get_shape(dataset,index)`. `N_train` and `N_test` are the number of training and testing shapes in each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/stress_nodal_features.npy\"\n",
    "dataset_train, dataset_test, X_train, X_test, y_train, y_test = load_dataset(data_path)\n",
    "N_train = len(dataset_train[\"stress\"])\n",
    "N_test = len(dataset_test[\"stress\"])\n",
    "\n",
    "plt.figure(figsize=[15,3.2], dpi=150)\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plot_shape(dataset_train,i)\n",
    "    plt.title(f\"Shape {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network to predict stress\n",
    "\n",
    "Create a PyTorch neural network class `StressPredictor` below. This should be an MLP with 60 inputs (the given features) and 1 output (stress). The hidden layer sizes and activations are up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StressPredictor(nn.Module):\n",
    "    # YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "\n",
    "Below, you should define a function `train(model, dataset, lr, epochs)` that will train `model` on the data in `dataset` with the Adam optimizer for `epochs` epochs with a learning rate of `lr`.\n",
    "\n",
    "Because there are so many total nodes, you should treat each shape as a batch of nodes -- each epoch of training will require you to loop through each shape in the dataset in a random order, performing a step of gradient descent for each shape encountered. Your function should automatically generate a plot of the loss curve on training data.\n",
    "\n",
    "- You can use the provided `get_shape` to access feature and output tensors for each shape. \n",
    "- Use MSE as a your loss function.\n",
    "- Look into `np.random.permutation()` for generating a random index order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, lr, epochs):\n",
    "    # YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your Neural Network\n",
    "\n",
    "Now, create your neural network model and run your train function on the training dataset `dataset_train`.  \n",
    "Determining the right number of epochs and learning rate are up to you. The training loss curve should be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2$ Score\n",
    "\n",
    "Compute the $R^2$ Score on the training dataset. You will have to convert between tensors and arrays versions to use sklearn functions, or you can write your own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2$ Plots\n",
    "\n",
    "Now, generate predicted-vs-actual plots that display both data and a theoretical best fit line. Make 2 such plots - one for training data and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Shape $R^2$\n",
    "\n",
    "Because we have a unique problem where groups of nodes in a dataset form a single shape, we can compute an $R^2$ score for an individual shape.\n",
    "For each shape in the training set, compute an $R^2$ score. Then create a histogram of the values with the function `plot_r2_hist(r2s)`. Repeat for the testing set.\n",
    "\n",
    "Report the median $R^2$ score across all training shapes, and the median across all testing shapes.\n",
    "\n",
    "If your test median is below 0.85, try and tune your network size/training hyperparameters until it reaches this threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
