{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  HW1 Programming Problem 4 (30 points)\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "In this problem you will implement gradient descent on the following function: $f(x) = x^2 + 3x +6\\textrm{sin}(x)$. You will define your own gradient function $\\texttt{fgrad}(x)$, and then using the provided learning rate $\\eta = 0.15$ and initial guess $x_0 = 8$, you will print the value of $x$ and $f(x)$ for the first 10 iterations.\n",
    "\n",
    "\n",
    "Fill out the notebook as instructed, making the requested plots and printing necessary values. \n",
    "\n",
    "#### Summary of deliverables:\n",
    "Functions:\n",
    "- `fgrad(x)`\n",
    "\n",
    "Results:\n",
    "- Printed values of $x$ and $f(x)$ for the first 10 iterations of gradient descent\n",
    "\n",
    "Discussion:\n",
    "- Do your printed values appear to be converging towards the minimum of the function?\n",
    "\n",
    "Imports and provided functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 6*np.sin(x)\n",
    "\n",
    "def plotfx():\n",
    "    # Sample function\n",
    "    xs = np.linspace(-12,10,100)\n",
    "    ys = f(xs)\n",
    "    # Plot function\n",
    "    plt.plot(xs,ys,'r-')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$f(x)$')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the function\n",
    "plotfx()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First define the function $\\texttt{fgrad}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fgrad(x) function goes here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the following code with the gradient descent update rule\n",
    "For reference, your 10th iteration should have $x = -1.554$ and $f(x) = -8.246$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 10\n",
    "eta = 0.15\n",
    "x = 8\n",
    "\n",
    "for i in range(iter):\n",
    "    # YOUR GRADIENT DESCENT CODE GOES HERE\n",
    "\n",
    "    \n",
    "    print('Iteration %d, x = %.3f, f(x) = %.3f' %(i+1, x, f(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Briefly discuss whether your printed values of $x$ and $f(x)$ appear to have converged to the minimum of the function. \n",
    "Feel free to refer to the provided plot of $f(x)$ above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your response goes here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
