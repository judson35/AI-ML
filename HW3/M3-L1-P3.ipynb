{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Problem 3 (5 points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IKUvVL4z7L5"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_data(data, c, title=\"\", xlabel=\"$x_1$\",ylabel=\"$x_2$\",classes=[\"\",\"\"],alpha=1):\n","    N = len(c)\n","    colors = ['royalblue','crimson']\n","    symbols = ['o','s']\n","    \n","    plt.figure(figsize=(5,5),dpi=120)\n","\n","    for i in range(2):\n","        x = data[:,0][c==i]\n","        y = data[:,1][c==i]\n","\n","        plt.scatter(x,y,color=colors[i],marker=symbols[i],edgecolor=\"black\",linewidths=0.4,label=classes[i],alpha=alpha)\n","\n","    plt.legend(loc=\"upper right\")\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    ax = plt.gca()\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    plt.xlim([-0.05,1.05])\n","    plt.ylim([-0.05,1.05])\n","    plt.title(title)\n","\n","def plot_contour(predict, mapXY = None):\n","    res = 500\n","    vals = np.linspace(-0.05,1.05,res)\n","    x,y = np.meshgrid(vals,vals)\n","    XY = np.concatenate((x.reshape(-1,1),y.reshape(-1,1)),axis=1)\n","    if mapXY is not None:\n","        XY = mapXY(XY)\n","    contour = predict(XY).reshape(res, res)\n","    plt.contour(x, y, contour)\n"]},{"cell_type":"markdown","metadata":{"id":"hgbeJjaQz7L6"},"source":["## Generate Dataset\n","#### (Don't edit this code.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHBLTsTpz7L7"},"outputs":[],"source":["def sample_ring(N,x,y,ro,ri):\n","    theta = np.random.rand(N)*2*np.pi\n","    r = np.random.rand(N)\n","    r = np.sqrt(r*(ro**2-ri**2)+ri**2)\n","    xs = x + r * np.cos(theta)\n","    ys = y + r * np.sin(theta)\n","    return xs, ys\n","\n","def get_ring_dataset():\n","    np.random.seed(0)\n","    c0 = sample_ring(70,0.5,0.5,0.5,0.3)\n","    c1 = sample_ring(60,0.45,0.47,0.36,0.15)\n","    xs = np.concatenate([c0[0],c1[0]],0)\n","    ys = np.concatenate([c0[1],c1[1]],0)\n","    c = np.concatenate([np.zeros(70),np.ones(60)],0)\n","    return np.vstack([xs,ys]).T, c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5FmtEAcz7L8"},"outputs":[],"source":["data, classes = get_ring_dataset()\n","format = dict(xlabel=\"Initial Speed\",ylabel=\"Launch Angle\", classes=[\"0 - Misses target\", \"1 - Hits target\"])\n","\n","plot_data(data, classes, **format)"]},{"cell_type":"markdown","metadata":{"id":"EaHhiWnnz7L8"},"source":["## Feature Expansion\n","\n","Define a function to expand 2 features into more features\n","For the features $x_1$ and $x_2$, expand into:\n","- $1$\n","- $x_1$\n","- $x_2$\n","- $x_1^2$\n","- $x_2^2$\n","- $\\sin(x_1)$\n","- $\\cos(x_1)$\n","- $\\sin(x_2)$\n","- $\\cos(x_2)$\n","- $\\sin^2(x_1)$\n","- $\\cos^2(x_1)$\n","- $\\sin^2(x_2)$\n","- $\\cos^2(x_2)$\n","- $\\exp(x_1)$\n","- $\\exp(x_2)$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1iwHxU4z7L8"},"outputs":[],"source":["def feature_expand(x):\n","    x1 = x[:,0].reshape(-1, 1)\n","    x2 = x[:,1].reshape(-1, 1)\n","\n","    # YOUR CODE GOES HERE:\n","    columns = [np.ones_like(x1), x1, x2] # Add all expanded features to this list\n","\n","    X = np.concatenate(columns, axis=1)\n","    return X\n","\n","features = feature_expand(data)\n","print(\"Dataset size:\", np.shape(data))\n","print(\"Expanded dataset size:\", np.shape(features))\n"]},{"cell_type":"markdown","metadata":{"id":"HjDNuieWz7L9"},"source":["## Logistic Regression\n","Use SciKit-Learn's Logistic Regression model to learn the decision boundary for this data, using regularization. (The `C` argument controls regularization strength.)\n","\n","Train this model on your expanded feature set.\n","\n","\n","Details about how to use this are here:\n","https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","\n","Notes:\n","- $\\lambda$ is related to sklearn's regularization strength $C$ by: $\\lambda = 1/C$\n","- You may want to increase the maximum number of iterations\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecwLs_PUz7L9"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","def get_logistic_regressor(features, classes, L = 1):\n","    # YOUR CODE GOES HERE\n","    # - Instantiate model with regularization\n","    # - Fit model to expanded data\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeyOZF8mz7L9"},"outputs":[],"source":["for L in [1e-9, 1e-1, 1]:\n","    model = get_logistic_regressor(features, classes, L)\n","    plot_data(data, classes, **format, title=f\"$\\lambda={L}$\")\n","    plot_contour(model.predict, feature_expand)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Pjfk9UQ6z7L-"},"source":["As $\\lambda$ increases, note what happens to the decision boundary. Why does this occur?"]},{"cell_type":"markdown","metadata":{"id":"jNYlJbcgz7L-"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"torch_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
