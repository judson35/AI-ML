{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9 (20 Points)\n",
    "## Problem description\n",
    "So far, we have worked with ~2 dimensional problems with 2-3 classes. Most often in ML, there are many more explanatory variables and classes than this. In this problem, you'll be training logistic regression models on a database of grayscale images of hand-drawn digits, using SciKit-Learn. Now there are 400 (20x20) input features and 10 classes (digits 0-9).\n",
    "\n",
    "As usual, you can use any code from previous problems.\n",
    "\n",
    "## Summary of deliverables\n",
    "- OvR model accuracy on training data\n",
    "- OvR model accuracy on testing data\n",
    "- Multinomial model accuracy on training data\n",
    "- Multinomial model accuracy on testing data\n",
    "\n",
    "\n",
    "### Imports and Utility Functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def visualize(xdata, index, title=\"\"):\n",
    "    image = xdata[index,:].reshape(20,20).T\n",
    "    plt.figure()\n",
    "    plt.imshow(image,cmap = \"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The following cell loads in training and testing data into the following variables:\n",
    "- `x_train`: 4000x400 array of input features, used for training\n",
    "- `y_train`: Array of ground-truth classes for each point in `x_train`\n",
    "- `x_test`: 1000x400 array of input features, used for testing\n",
    "- `y_test`: Array of ground-truth classes for each point in `x_test`\n",
    "\n",
    "\n",
    "You can visualize a digit with the `visualize(x_data, index)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.load(\"data/w3-hw3-train_x.npy\")\n",
    "y_train = np.load(\"data/w3-hw3-train_y.npy\")\n",
    "x_test = np.load(\"data/w3-hw3-test_x.npy\")\n",
    "y_test = np.load(\"data/w3-hw3-test_y.npy\")\n",
    "\n",
    "visualize(x_train,1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models\n",
    "\n",
    "Use sklearn's `LogisticRegression` to fit a multinomial logistic regression model on the training data. You may need to increase the `max_iter` argument for the model to converge.\n",
    "\n",
    "Train 2 models: one using the One-vs-Rest method, and another that minimizes multinomial loss. You can do these by setting the `multi_class` argument to \"ovr\" and \"multinomial\", respectively.  \n",
    "\n",
    "More information: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='multinomial')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LogisticRegression(max_iter=10000, multi_class=\"ovr\")\n",
    "model_2 = LogisticRegression(max_iter=10000, multi_class=\"multinomial\")\n",
    "\n",
    "model_1.fit(x_train, y_train)\n",
    "model_2.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Compute and print the accuracy of each model on the training and testing sets as a percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Train Accuracy (Model 1):  94.72500000000001 %\n",
      "    Test Accuracy (Model 1):  90.7 %\n",
      "    Train Accuracy (Model 2):  96.475 %\n",
      "    Test Accuracy (Model 2):  91.4 %\n"
     ]
    }
   ],
   "source": [
    "train_preds_1 = model_1.predict(x_train)\n",
    "train_preds_2 = model_2.predict(x_train)\n",
    "test_preds_1 = model_1.predict(x_test)\n",
    "test_preds_2 = model_2.predict(x_test)\n",
    "\n",
    "train_accuracy_1 = np.sum(train_preds_1 == y_train) / len(y_train) * 100\n",
    "test_accuracy_1 = np.sum(test_preds_1 == y_test) / len(y_test) * 100\n",
    "train_accuracy_2 = np.sum(train_preds_2 == y_train) / len(y_train) * 100\n",
    "test_accuracy_2 = np.sum(test_preds_2 == y_test) / len(y_test) * 100\n",
    "print(\"    Train Accuracy (Model 1): \", train_accuracy_1, r\"%\")\n",
    "print(\"    Test Accuracy (Model 1): \", test_accuracy_1, r\"%\")\n",
    "print(\"    Train Accuracy (Model 2): \", train_accuracy_2, r\"%\")\n",
    "print(\"    Test Accuracy (Model 2): \", test_accuracy_2, r\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
