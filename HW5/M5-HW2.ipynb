{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 (30 Points)\n",
    "\n",
    "## Problem Description\n",
    "In this problem, you are given a dataset with two input features and one output. You will use a regression tree to make predictions for this data, evaluating each model on both training and testing data. Then, you will repeat this for multiple random forests.\n",
    "\n",
    "Fill out the notebook as instructed, making the requested plots and printing necessary values. \n",
    "\n",
    "*You are welcome to use any of the code provided in the lecture activities.*\n",
    "\n",
    "#### Summary of deliverables:\n",
    "- RMSE function\n",
    "- Create 4 decision tree prediction surface plots\n",
    "- Create 4 random forest prediction surface plots\n",
    "- Print RMSE for train and test data for 4 decision tree models\n",
    "- Print RMSE for train and test data for 4 random forest models\n",
    "- Answer the 3 questions posed throughout\n",
    "\n",
    "#### Imports and Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "def make_plot(X,y,model, title=\"\"):\n",
    "    res = 100\n",
    "    xrange = np.linspace(min(X[:,0]),max(X[:,0]),res)\n",
    "    yrange = np.linspace(min(X[:,1]),max(X[:,1]),res)\n",
    "    x1,x2 = np.meshgrid(xrange,yrange)\n",
    "    xmesh = np.vstack([x1.flatten(),x2.flatten()]).T\n",
    "    z = model.predict(xmesh).reshape(res,res)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    plt.subplots_adjust(left=0.3,right=0.9,bottom=.3,top=.9)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(x1,x2,z,cmap=cm.coolwarm,linewidth=0,alpha=0.9)\n",
    "    ax.scatter(X[:,0],X[:,1],y,'o',c='black')\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.set_zlabel('y')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Use the `np.load()` function to load \"w5-hw2-train.npy\" (training data) and \"w5-hw2-test.npy\" (testing data). The first two columns of each are the input features. The last column is the output.\n",
    "You should end up with 4 variables, input and output for each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE function\n",
    "Complete a root-mean-squared-error function, `RMSE(y, pred)`, which takes in two arrays, and computes the RMSE between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, pred):\n",
    "    # YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression trees\n",
    "\n",
    "Train 4 regression trees in sklearn, with max depth values [2,5,10,25]. Train your models on the training data.\n",
    "\n",
    "Plot the predictions as a surface plot along with test points -- you can use the provided function: `make_plot(X, y, model, title)`.  \n",
    "For each model, compute the train and test RMSE by calling your RMSE function. Print these results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- Which of your regression trees performed the best on testing data?  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression trees\n",
    "\n",
    "Train 4 random forests in sklearn. For all of them, use the max depth values from your best-performing regression tree. The number of estimators should vary, with values [5, 10, 25, 100]. \n",
    "\n",
    "Plot the predictions as a surface plot along with test points.\n",
    "Once again, for each model, compute the train and test RMSE by calling your RMSE function. Print these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- Which of your random forests performed the best on testing data?  \n",
    "\n",
    "\n",
    "- How does the random forest prediction surface differ qualitatively from that of the decision tree? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
