{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Consider a 2D robotic arm with 3 links. The position of its end-effector is governed by the arm lengths and joint angles as follows (as in the figure \"data/robot-arm.png\"):\n",
    "$$\n",
    "x = L_1 \\cos(\\theta_1) + L_2\\cos(\\theta_2+\\theta_1) + L_3\\cos(\\theta_3+\\theta_2+\\theta_1)\\\\\n",
    "y = L_1\\sin(\\theta_1) + L_2\\sin(\\theta_2+\\theta_1) + L_3\\sin(\\theta_3+\\theta_2+\\theta_1)\n",
    "$$\n",
    "\n",
    "In robotics settings, inverse-kinematics problems are common for setups like this. For example, suppose all 3 arm lengths are $L_1 = L_2 = L_3 = 1$, and we want to position the end-effector at $(x,y) = (0.5, 0.5)$. What set of joint angles $(\\theta_1, \\theta_2, \\theta_3)$ should we choose for the end-effector to reach this position?\n",
    "\n",
    "In this problem you will train a neural network to find a function mapping from coordinates $(x,y)$ to joint angles $(\\theta_1, \\theta_2, \\theta_3)$ that position the end-effector at $(x,y)$.\n",
    "\n",
    "\n",
    "\n",
    "#### Summary of deliverables:\n",
    "\n",
    "1. Neural network model\n",
    "\n",
    "2. Generate training and validation data\n",
    "\n",
    "3. Training function\n",
    "\n",
    "4. 6 plots with training and validation loss\n",
    "\n",
    "5. 6 prediction plots\n",
    "\n",
    "6. Respond to the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "class ForwardArm(nn.Module):\n",
    "    def __init__(self, L1=1, L2=1, L3=1):\n",
    "        super().__init__()\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "        self.L3 = L3\n",
    "    def forward(self, angles):\n",
    "        theta1 = angles[:,0]\n",
    "        theta2 = angles[:,1]\n",
    "        theta3 = angles[:,2]\n",
    "        x = self.L1*torch.cos(theta1) + self.L2*torch.cos(theta1+theta2) + self.L3*torch.cos(theta1+theta2+theta3)\n",
    "        y = self.L1*torch.sin(theta1) + self.L2*torch.sin(theta1+theta2) + self.L3*torch.sin(theta1+theta2+theta3)\n",
    "        return torch.vstack([x,y]).T\n",
    "\n",
    "def plot_predictions(model, title=\"\"):\n",
    "    fwd = ForwardArm()\n",
    "\n",
    "    vals = np.arange(0.1, 2.0, 0.2)\n",
    "    x, y = np.meshgrid(vals,vals)\n",
    "    coords = torch.tensor(np.vstack([x.flatten(),y.flatten()]).T,dtype=torch.float)\n",
    "    angles = model(coords)\n",
    "    preds = fwd(angles).detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=[4,4],dpi=140)\n",
    "\n",
    "    plt.scatter(x.flatten(), y.flatten(), s=60, c=\"None\",marker=\"o\",edgecolors=\"k\", label=\"Targets\")\n",
    "    plt.scatter(preds[:,0], preds[:,1], s=25, c=\"red\", marker=\"o\", label=\"Predictions\")\n",
    "    plt.text(0.1, 2.15, f\"MSE = {nn.MSELoss()(fwd(model(coords)),coords):.1e}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim(-.1,2.1)\n",
    "    plt.ylim(-.1,2.4)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_arm(theta1, theta2, theta3, L1=1,L2=1,L3=1, show=True):\n",
    "    x1 = L1*np.cos(theta1)\n",
    "    y1 = L1*np.sin(theta1)\n",
    "    x2 = x1 + L2*np.cos(theta1+theta2)\n",
    "    y2 = y1 + L2*np.sin(theta1+theta2)\n",
    "    x3 = x2 + L3*np.cos(theta1+theta2+theta3)\n",
    "    y3 = y2 + L3*np.sin(theta1+theta2+theta3)\n",
    "    xs = np.array([0,x1,x2,x3])\n",
    "    ys = np.array([0,y1,y2,y3])\n",
    "\n",
    "    plt.figure(figsize=(5,5),dpi=140)\n",
    "    plt.plot(xs, ys, linewidth=3, markersize=5,color=\"gray\", markerfacecolor=\"lightgray\",marker=\"o\",markeredgecolor=\"black\")\n",
    "    plt.scatter(x3,y3,s=50,color=\"blue\",marker=\"P\",zorder=100)\n",
    "    plt.scatter(0,0,s=50,color=\"black\",marker=\"s\",zorder=-100)\n",
    "    \n",
    "    plt.xlim(-1.5,3.5)\n",
    "    plt.ylim(-1.5,3.5)\n",
    "\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-effector position\n",
    "\n",
    "You can use the interactive figure below to visualize the robot arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout, FloatSlider, Dropdown\n",
    "\n",
    "def plot_unit_arm(theta1, theta2, theta3):\n",
    "    plot_arm(theta1, theta2, theta3)\n",
    "\n",
    "slider1 = FloatSlider(value=0, min=-np.pi*0.75, max=np.pi*0.75, step=np.pi/100, description='theta1',disabled=False,continuous_update=True,orientation='horizontal',readout=False,layout = Layout(width='550px'))\n",
    "slider2 = FloatSlider(value=0, min=-np.pi*0.75, max=np.pi*0.75, step=np.pi/100, description='theta2',disabled=False,continuous_update=True,orientation='horizontal',readout=False,layout = Layout(width='550px'))\n",
    "slider3 = FloatSlider(value=0, min=-np.pi*0.75, max=np.pi*0.75, step=np.pi/100, description='theta3',disabled=False,continuous_update=True,orientation='horizontal',readout=False,layout = Layout(width='550px'))\n",
    "\n",
    "interactive_plot = interactive(plot_unit_arm, theta1 = slider1, theta2 = slider2, theta3 = slider3)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '600px'\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Inverse Kinematics\n",
    "In this class we have mainly had regression problems with only one output. However, you can create neural networks with any number of outputs just by changing the size of the last layer. For this problem, we already know the function to go from joint angles (3) to end-effector coordinates (2). This is provided in neural network format as `ForwardArm()`.\n",
    "\n",
    "If you provide an instance of `ForwardArm()` with an $N\\times3$ tensor of joint angles, and it will return an $N\\times2$ tensor of coordinates.\n",
    "\n",
    "Here, you should create a neural network with 2 inputs and 3 outputs that, once trained, can output the joint angles (in radians) necessary to reach the input x-y coordinates.\n",
    "\n",
    "In the cell below, complete the definition for `InverseArm()`:\n",
    "- The initialization argument `hidden_layer_sizes` dictates the number of neurons per hidden layer in the network. For example, `hidden_layer_sizes=[12,24]` should create a network with 2 inputs, 12 neurons in the first hidden layer, 24 neurons in the second hidden layer, and 3 outputs.\n",
    "- Use a ReLU activation at the end of each hidden layer.\n",
    "- The initialization argument `max_angle` refers to the maximum bend angle of the joint. If `max_angle=None`, there should be no activation at the last layer. However, if `max_angle=1` (for example), then the output joint angles should be restricted to the interval [-1, 1] (radians). You can clamp values with the tanh function (and then scale them) to achieve this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseArm(nn.Module):\n",
    "    def __init__(self, hidden_layer_sizes=[24,24], max_angle=None):\n",
    "        super().__init__()\n",
    "        # YOUR CODE GOES HERE\n",
    "\n",
    "    def forward(self, xy):\n",
    "        # YOUR CODE GOES HERE\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, generate a dataset of x-y coordinates. You should use a $100\\times 100$ meshgrid, for x and y each on the interval $[0, 2]$.  \n",
    "\n",
    "Randomly split your data so that 80% of points are in `X_train`, while the remaining 20% are in `X_val`. (Each of these should have 2 columns -- x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "\n",
    "Write a function `train()` below with the following specifications:\n",
    "\n",
    "*Inputs:*  \n",
    "- `model`: `InverseArm` model to train\n",
    "- `X_train`: $N\\times 2$ vector of training x-y coordinates\n",
    "- `X_val`: $N\\times 2$ vector of validation x-y coordinates\n",
    "- `lr`: Learning rate for Adam optimizer\n",
    "- `epochs`: Total epoch count\n",
    "- `gamma`: ExponentialLR decay rate\n",
    "- `create_plot`: (`True`/`False`) Whether to display a plot with training and validation loss curves\n",
    "\n",
    "*Loss function:*  \n",
    "The loss function you use should be based on whether the end-effector moves to the correct location. It should be the MSE between the target coordinate tensor and the coordinates that the predicted joint angles produce. In other words, if your inverse kinematics model is `model`, and `fwd` is an instance of `ForwardArm()`, then you want the MSE between input coordinates `X` and `fwd(model(X))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, X_val, lr = 0.01, epochs = 1000, gamma = 1, create_plot = True):\n",
    "    # YOUR CODE GOES HERE\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Create 3 models of different complexities (with `max_angle=None`):\n",
    "- `hidden_layer_sizes=[12]`\n",
    "- `hidden_layer_sizes=[24,24]`\n",
    "- `hidden_layer_sizes=[48,48,48]`\n",
    "\n",
    "Train each model for 1000 epochs, learning rate 0.01, and gamma 0.995. Show the plot for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "For each of your models, use the function `plot_predictions` to visualize model predictions on the domain. You should observe improvements with increasing network size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization\n",
    "\n",
    "\n",
    "You can use the interactive plot below to look at the performance of your model. (The model used must be named `model`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout, FloatSlider, Dropdown\n",
    "\n",
    "def plot_inverse(x, y):\n",
    "    xy = torch.Tensor([[x,y]])\n",
    "    theta1, theta2, theta3 = model(xy).detach().numpy().flatten().tolist()\n",
    "    plot_arm(theta1, theta2, theta3, show=False)\n",
    "    plt.scatter(x, y, s=100, c=\"red\",zorder=1000,marker=\"x\")\n",
    "    plt.plot([0,2,2,0,0],[0,0,2,2,0],c=\"lightgray\",linewidth=1,zorder=-1000)\n",
    "    plt.show()\n",
    "\n",
    "slider1 = FloatSlider(value=1, min=-.5, max=2.5, step=1/100, description='x', disabled=False, continuous_update=True, orientation='horizontal', readout=False, layout = Layout(width='550px'))\n",
    "slider2 = FloatSlider(value=1, min=-.5, max=2.5, step=1/100, description='y', disabled=False, continuous_update=True, orientation='horizontal', readout=False, layout = Layout(width='550px'))\n",
    "\n",
    "interactive_plot = interactive(plot_inverse, x = slider1, y = slider2)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '600px'\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training more neural networks\n",
    "\n",
    "Now train more networks with the following details:\n",
    "1. `hidden_layer_sizes=[48,48], max_angle=torch.pi/2`, train with `lr=0.01, epochs=1000, gamma=.995`\n",
    "2. `hidden_layer_sizes=[48,48], max_angle=None`, train with `lr=1, epochs=1000, gamma=1`\n",
    "3. `hidden_layer_sizes=[48,48], max_angle=2`, train with `lr=0.0001, epochs=300, gamma=1`\n",
    "\n",
    "For each network, show a loss curve plot and a `plot_predictions` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "Neither of these models should have great performance.\n",
    "Describe what went wrong in each case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
