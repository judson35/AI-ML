{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M11-L2 Problem 1\n",
    "\n",
    "In this problem you will implement the elbow method using three different sklearn clustering algorithms: (`KMeans`, `SpectralClustering`, `GaussianMixture`). You will use the algorithms to find the number of natural clusters for two different datasets, one \"blob\" shaped dataset, and one concetric circle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def plot_loss(loss, ax = None, title = None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.plot(np.arange(2, len(loss)+2), loss, 'k-o')\n",
    "    ax.set_xlabel('Number of Clusters')\n",
    "    ax.set_ylabel('Loss')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def plot_pred(x, labels, ax = None, title = None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    n_clust = len(np.unique(labels))\n",
    "    for i in range(n_clust):\n",
    "        ax.scatter(x[labels == i,0], x[labels == i,1], alpha = 0.5)\n",
    "    ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def compute_loss(x, labels):\n",
    "    # Initialize loss\n",
    "    loss = 0\n",
    "    # Number of clusters\n",
    "    n_clust = len(np.unique(labels))\n",
    "    # Loop through the clusters\n",
    "    for i in range(n_clust):\n",
    "        # Compute the center of a given label\n",
    "        center = np.mean(x[labels == i, :], axis = 0)\n",
    "        # Compute the sum of squared distances between each point and its corresponding cluster center\n",
    "        loss += np.sum(np.linalg.norm(x[labels == i, :] - center, axis = 1)**2)\n",
    "    return loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob dataset\n",
    "\n",
    "Visualize the \"blob\" dataset generated below, using a unique color for each cluster of points, where `y` contains the label of each corresponding point in `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY\n",
    "x, y = make_blobs(n_samples = 1000, n_features = 2, centers = [[0,0],[2,2],[1,-2],[4,0],[-2,-1],[-1,3]], cluster_std = [0.6,0.4,0.6,1.5,0.3,0.8], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `sklearn` KMeans, Spectral Clustering, and Gaussian Mixture Model functions to cluster the \"blob\" data with 6 clusters, and modify the parameters until you get satisfactory results. Plot the results of your three models side-by-side using `plt.subplots` and the provided `plot_pred(x, labels, ax, title)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters you found for the three models above, run each of the clustering algorithms for `n_clust = [2,3,4,5,6,7,8,9]` and compute the sum of squared distances loss for each case using the provided `compute_loss(x, labels)` function, where labels is the cluster assigned to each point by the algorithm. Plot loss versus number of cluster for each your three models in side-by-side subplots using the provided `plot_pred(x, labels, ax, title)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentric circles dataset\n",
    "Visualize the \"blob\" dataset generated below, using a unique color for each cluster of points, where `y` contains the label of each corresponding point in `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT MODIFY\n",
    "x1, y1 = make_circles(n_samples = 400, noise = 0.05, factor = 0.5, random_state = 0)\n",
    "x2, y2 = make_circles(n_samples = 800, noise = 0.025, factor = 0.75, random_state = 1)\n",
    "\n",
    "x = np.vstack([x1, x2*2])\n",
    "y = np.hstack([y1, y2+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `sklearn` KMeans, Spectral Clustering, and Gaussian Mixture Model functions to cluster the concentric circle data with 4 clusters, and attempt to modify the parameters until you get satisfactory results. Note: you should get good clustering results with Spectral Clustering, but the KMeans and GMM models will struggle to cluster this dataset well. Plot the results of your three models side-by-side using `plt.subplots` and the provided `plot_pred(x, labels, ax, title)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameters you found for the three models above, run each of the clustering algorithms for `n_clust = [2,3,4,5,6,7,8,9]` and compute the sum of squared distances loss for each case using the provided `compute_loss(x, labels)` function, where labels is the cluster assigned to each point by the algorithm. Plot loss versus number of cluster for each your three models in side-by-side subplots using the provided `plot_pred(x, labels, ax, title)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "1. Discuss the performance of the clustering algorithms on the \"blob\" dataset. Using the elbow method, were you able to identify the number of natural clusters in the dataset for each of the methods? Does the elbow method work better for some algorithms versus others?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your response goes here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Discuss the performance of the clustering algorithms on the concentric circles dataset. Using the elbow method, were you able to identify the number of natural clusters in the dataset for each of the methods?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your response goes here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Does the sum of squared distances work well as a loss function for each of the three clustering algorithms we implemented? Does the sum of squared distance fail on certain types of clusters?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your response goes here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
