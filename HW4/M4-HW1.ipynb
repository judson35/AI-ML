{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 (20 points)\n",
    "\n",
    "## Problem Description\n",
    "As a lecture activity, you performed support vector classification on a linearly separable dataset by solving the quadratic programming optimization problem to create a large margin classifier.\n",
    "\n",
    "Now, you will use a similar approach to create a soft margin classifier on a dataset that is not cleanly separable.\n",
    "\n",
    "Fill out the notebook as instructed, making the requested plots and printing necessary values. \n",
    "\n",
    "*You are welcome to use any of the code provided in the lecture activities.*\n",
    "\n",
    "#### Summary of deliverables:\n",
    "Functions (described later):\n",
    "- `soft_margin_svm(X,y,C)`\n",
    "\n",
    "Results:\n",
    "- Print the values of w1, w2, and b for the C=0.05 case\n",
    "\n",
    "Plots:\n",
    "- Plot the data with the optimized margin and decision boundary for the case C=0.05\n",
    "- Make 4 such plots for the requested C values\n",
    "\n",
    "Discussion:\n",
    "- Respond to the prompt asked at the end of the notebook\n",
    "\n",
    "#### Imports and Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "solvers.options['show_progress'] = False\n",
    "\n",
    "def plot_boundary(x, y, w1, w2, b, e=0.1):\n",
    "    x1min, x1max = min(x[:,0]), max(x[:,0])\n",
    "    x2min, x2max = min(x[:,1]), max(x[:,1])\n",
    "    \n",
    "    xb = np.linspace(x1min,x1max)\n",
    "    y_0 = 1/w2*(-b-w1*xb)\n",
    "    y_1 = 1/w2*(1-b-w1*xb)\n",
    "    y_m1 = 1/w2*(-1-b-w1*xb)\n",
    "    \n",
    "    cmap = ListedColormap([\"purple\",\"orange\"])\n",
    "\n",
    "    plt.scatter(x[:,0],x[:,1],c=y,cmap=cmap)\n",
    "    plt.plot(xb,y_0,'-',c='blue')\n",
    "    plt.plot(xb,y_1,'--',c='green')\n",
    "    plt.plot(xb,y_m1,'--',c='green')\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    plt.axis((x1min-e,x1max+e,x2min-e,x2max+e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Data is loaded as follows:  \n",
    "- X: input features, Nx2 array  \n",
    "- y: output class, length N array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/w4-hw1-data.npy\")\n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Margin SVM Optimization Problem\n",
    "\n",
    "For soft-margin SVM, we introduce N slack variables $\\xi_i$ (one for each point), and reformulate the optimization problem as:\n",
    "\n",
    "$$\n",
    "\\min_{\\boldsymbol{w}, b}\\qquad \\frac{1}{2}||\\boldsymbol{w}||^2 + C \\sum_i \\xi_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{subject to:}\\quad y_i(\\boldsymbol{w}^T \\boldsymbol{x}_i+b)\\geq 1 - \\xi_i;\\quad \\xi_i \\geq 0\n",
    "$$\n",
    "\n",
    "To put this into a form compatible with `cvxopt`, we will need to assemble large matrices as described in the next section.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Margin SVM function\n",
    "\n",
    "Define a function `soft_margin_svm(X, y, C)` with inputs:\n",
    "- `X`: (Nx2) array of input features\n",
    "- `y`: Length N array of output classes, -1 or 1\n",
    "- `C`: Regularization parameter\n",
    "\n",
    "In this function, do the following steps:\n",
    "\n",
    "1. Create the P, q, G, and h arrays for this problem (each comprised of multiple sub-matrices you need to combine into one)\n",
    "- `P`: (3+N) x (3+N)\n",
    "  - Upper left: Identity matrix, but with 0 instead of 1 for the bias (third) row/column\n",
    "  - Upper right (3xN): Zeros\n",
    "  - Lower left (Nx3): Zeros\n",
    "  - Lower right: (NxN): Zeros\n",
    "- `q`: (3+N) x (1)\n",
    "  - Top (3x1): Vector of zeros\n",
    "  - Bottom (Nx1): Vector filled with 'C'\n",
    "- `G`: (N+N) x (N+3): \n",
    "  - Upper left (Nx3): Negative y multiplied element-wise by [`x1`, `x2`, `1`]\n",
    "  - Upper right (NxN): Negative identity matrix\n",
    "  - Lower left (Nx3): Zeros\n",
    "  - Lower right (NxN): Negative identity matrix\n",
    "- `h`: (N+N) x (1)\n",
    "  - Top: Vector of -1\n",
    "  - Bottom: Vector of zeros\n",
    "\n",
    "You can use `np.block()` to combine multiple submatrices into one.\n",
    "\n",
    "2. Convert each of these into cvxopt matrices (Provided)\n",
    "\n",
    "3. Solve the problem using `cvxopt.solvers.qp` (Provided)\n",
    "\n",
    "4. Extract the `w1`, `w2`, and `b` values from the solution, and return them (Provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_margin_svm(X, y, C):\n",
    "    N = np.shape(X)[0]\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "    # Define P, q, G, h\n",
    "\n",
    "    z = solvers.qp(matrix(P),matrix(q),matrix(G),matrix(h))\n",
    "    w1 = z['x'][0]\n",
    "    w2 = z['x'][1]\n",
    "    b  = z['x'][2]\n",
    "\n",
    "    return w1, w2, b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: C = 0.05\n",
    "Run the cell below to create the plot for the N = 0.05 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.05\n",
    "w1, w2, b = soft_margin_svm(X, y, C)\n",
    "print(f\"\\nSolution\\n--------\\nw1: {w1:8.4f}\\nw2: {w2:8.4f}\\n b: {b:8.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plot_boundary(X,y,w1,w2,b,e=1)\n",
    "plt.title(f\"C = {C}\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying C\n",
    "Now loop over the C values [1e-5, 1e-3, 1e-2, 1] and generate soft margin decision boundary plots like the one above for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Please write a sentence or two discussing what happens to the decision boundary and margin as you vary C, and try to provide some rationale for why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
